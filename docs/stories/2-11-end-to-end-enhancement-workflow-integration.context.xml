<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>2.11</storyId>
    <title>End-to-End Enhancement Workflow Integration</title>
    <status>drafted</status>
    <generatedAt>2025-11-02</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/2-11-end-to-end-enhancement-workflow-integration.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>system integrator</asA>
    <iWant>all components connected in working end-to-end flow</iWant>
    <soThat>a webhook triggers complete ticket enhancement</soThat>
    <tasks>
### Task 1: Implement Complete `enhance_ticket` Celery Task
- 1.1 Update Celery task signature
- 1.2 Generate correlation ID at task start
- 1.3 Load tenant configuration from database
- 1.4 Create enhancement_history record with status='pending'

### Task 2: Orchestrate Context Gathering (Story 2.8 Integration)
- 2.1 Initialize LangGraph workflow with ticket context
- 2.2 Execute LangGraph workflow nodes
- 2.3 Handle context gathering failures gracefully

### Task 3: Integrate LLM Synthesis (Story 2.9 Integration)
- 3.1 Call LLM synthesis with gathered context
- 3.2 Handle LLM synthesis failures
- 3.3 Validate and truncate enhancement output

### Task 4: Update ServiceDesk Plus Ticket (Story 2.10 Integration)
- 4.1 Call ServiceDesk Plus API client
- 4.2 Handle API update result

### Task 5: Update Enhancement History Record
- 5.1 Calculate processing time
- 5.2 Update enhancement_history on success
- 5.3 Update enhancement_history on failure

### Task 6: Implement Integration Test for End-to-End Workflow
- 6.1 Create integration test file
- 6.2 Implement test: happy path (full success)
- 6.3 Implement test: partial context failure
- 6.4 Implement test: LLM synthesis failure with fallback
- 6.5 Implement test: ServiceDesk Plus API failure
- 6.6 Implement test: missing tenant configuration
- 6.7 Implement test: performance measurement (latency tracking)

### Task 7: Implement Correlation ID Propagation
- 7.1 Pass correlation_id to LangGraph workflow
- 7.2 Pass correlation_id to LLM synthesis
- 7.3 Pass correlation_id to ServiceDesk Plus API client
- 7.4 Verify correlation_id in logs

### Task 8: Implement Graceful Timeout Handling
- 8.1 Set task-level timeout (120 seconds total per NFR001)
- 8.2 Implement timeout for context gathering phase
- 8.3 Verify timeout handling in integration tests

### Task 9: Documentation and Validation
- 9.1 Update architecture documentation
- 9.2 Create runbook for enhancement failures
- 9.3 Validate against all acceptance criteria
    </tasks>
  </story>

  <acceptanceCriteria>
1. **Complete Pipeline Functional**
   - Webhook → Queue → Worker → Context Gathering → LLM → API Update pipeline operational
   - Integration test with sample webhook payload completes successfully
   - Test ticket updated in ServiceDesk Plus (or mock) with enhancement content
   - All intermediate steps logged with correlation ID

2. **Celery Task Integration**
   - `enhance_ticket` Celery task orchestrates Stories 2.8 (LangGraph), 2.9 (LLM), 2.10 (API)
   - Task accepts payload: `{"tenant_id": "...", "ticket_id": "...", "description": "...", "priority": "..."}`
   - Task loads tenant configuration (base_url, api_key) from database
   - Task executes LangGraph workflow to gather context
   - Task calls LLM synthesis to generate enhancement
   - Task calls ServiceDesk Plus API client to post enhancement
   - Task updates `enhancement_history` table with result

3. **Enhancement History Recording**
   - On success: Record status='completed', completed_at timestamp, processing_time_ms, llm_output, context_gathered
   - On failure: Record status='failed', error_message, completed_at timestamp
   - Include correlation_id for end-to-end request tracing
   - Store tenant_id, ticket_id for filtering and auditing

4. **Performance Requirements (NFR001 Compliance)**
   - End-to-end latency <60 seconds p95 (target from webhook to ticket update)
   - Measured: p50, p95, p99 latencies logged for performance baseline
   - Total timeout budget: 120 seconds (per NFR001), task fails gracefully if exceeded
   - Breakdown target: Context gathering (10-15s) + LLM synthesis (20-30s) + API update (5-10s) = ~45-55s typical

5. **Error Handling and Graceful Degradation**
   - Failed context nodes don't block enhancement (partial context acceptable per NFR003)
   - LLM synthesis failure falls back to formatted context without AI insights
   - ServiceDesk Plus API failure logged as ERROR, enhancement_history marked 'failed'
   - All errors logged with: correlation_id, tenant_id, ticket_id, error_message, stack_trace

6. **Logging with Correlation IDs**
   - Correlation ID generated at webhook receipt (UUID format)
   - Correlation ID passed through: Queue → Celery task → LangGraph → LLM → API client
   - All log statements include correlation_id for distributed tracing
   - Log levels used appropriately: INFO (milestones), WARNING (partial failures), ERROR (full failures), CRITICAL (security issues)

7. **Integration Testing**
   - Integration test simulates full workflow with mock ServiceDesk Plus webhook
   - Test validates: Queue job creation, Celery task execution, LangGraph workflow, LLM synthesis, API client call
   - Test asserts: enhancement_history record created with correct status
   - Test measures: end-to-end latency within acceptable range (<60s)
   - Mock external services (ServiceDesk Plus API, OpenRouter API) to avoid test flakiness
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>Functional Requirements (FR010-FR017, FR022-FR025)</section>
        <snippet>Enhancement workflow requirements: LangGraph orchestration (FR010), LLM synthesis with GPT-4 (FR011), 500-word limit (FR013), ticket update via API (FR015-FR017), monitoring/logging (FR022-FR025)</snippet>
      </doc>
      <doc>
        <path>docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>Non-Functional Requirements (NFR001, NFR003, NFR005)</section>
        <snippet>NFR001: End-to-end latency <60s p95, 120s timeout. NFR003: 99% reliability with graceful degradation. NFR005: Distributed tracing with correlation IDs, audit logs retained 90 days</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Decision Architecture</title>
        <section>Technology Stack - AI/ML and Message Queue</section>
        <snippet>LangGraph 1.0+ for workflow orchestration, OpenRouter API with GPT-4o-mini, Celery 5.x task queue with Redis broker, HTTPX async HTTP client, Loguru structured logging</snippet>
      </doc>
      <doc>
        <path>docs/tech-spec-epic-2.md</path>
        <title>Epic 2 Technical Specification</title>
        <section>System Architecture Alignment (lines 64-171)</section>
        <snippet>Complete pipeline flow: Webhook → Queue → Celery Worker → Context Gathering (Stories 2.5-2.7) → LangGraph Orchestration (2.8) → LLM Synthesis (2.9) → ServiceDesk Plus API Update (2.10). Parallel execution pattern reduces latency from ~30s to ~10-15s</snippet>
      </doc>
      <doc>
        <path>docs/tech-spec-epic-2.md</path>
        <title>Epic 2 Technical Specification</title>
        <section>Architectural Patterns</section>
        <snippet>Parallel context gathering, graceful degradation (failed nodes don't block), caching strategy (Redis 1hr TTL), retry logic at multiple layers, data provenance tracking with source tags</snippet>
      </doc>
      <doc>
        <path>docs/stories/2-8-integrate-langgraph-workflow-orchestration.md</path>
        <title>Story 2.8 - LangGraph Integration</title>
        <section>Implementation Summary</section>
        <snippet>WorkflowState TypedDict with parallel node execution (ticket_search, kb_search, ip_lookup). Graceful degradation: failed nodes don't block workflow. Returns WorkflowState with similar_tickets, kb_articles, ip_info, errors. Status: review</snippet>
      </doc>
      <doc>
        <path>docs/stories/2-9-integrate-openai-gpt4-for-context-synthesis.md</path>
        <title>Story 2.9 - LLM Synthesis</title>
        <section>Implementation Summary</section>
        <snippet>synthesize_enhancement(context: WorkflowState) -> str using OpenRouter API + GPT-4o-mini. 500-word limit enforced, 30s timeout, fallback to formatted context on failure. Token tracking for cost attribution. Status: done</snippet>
      </doc>
      <doc>
        <path>docs/stories/2-10-implement-servicedesk-plus-api-integration.md</path>
        <title>Story 2.10 - ServiceDesk Plus API Client</title>
        <section>Implementation Summary</section>
        <snippet>async update_ticket_with_enhancement(base_url, api_key, ticket_id, enhancement) -> bool. Retry logic: 3 attempts, exponential backoff (2s/4s/8s). Markdown-to-HTML conversion. 29 unit tests, 100% passing. Status: review</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/workers/tasks.py</path>
        <kind>celery_task</kind>
        <symbol>enhance_ticket</symbol>
        <lines>entire-file</lines>
        <reason>Main Celery task for end-to-end enhancement workflow - will be modified to orchestrate all integration steps</reason>
      </artifact>
      <artifact>
        <path>src/workflows/enhancement_workflow.py</path>
        <kind>workflow</kind>
        <symbol>execute_context_gathering</symbol>
        <lines>571-676</lines>
        <reason>LangGraph workflow executor from Story 2.8 - returns WorkflowState with gathered context</reason>
      </artifact>
      <artifact>
        <path>src/workflows/enhancement_workflow.py</path>
        <kind>class</kind>
        <symbol>WorkflowState</symbol>
        <lines>53-94</lines>
        <reason>TypedDict defining workflow state structure - contains similar_tickets, kb_articles, ip_info, errors, timing metrics</reason>
      </artifact>
      <artifact>
        <path>src/services/llm_synthesis.py</path>
        <kind>service</kind>
        <symbol>synthesize_enhancement</symbol>
        <lines>247-418</lines>
        <reason>LLM synthesis function from Story 2.9 - accepts WorkflowState, returns markdown enhancement (max 500 words)</reason>
      </artifact>
      <artifact>
        <path>src/services/servicedesk_client.py</path>
        <kind>service</kind>
        <symbol>update_ticket_with_enhancement</symbol>
        <lines>194-347</lines>
        <reason>ServiceDesk Plus API client from Story 2.10 - posts enhancement to ticket, returns bool (True=success)</reason>
      </artifact>
      <artifact>
        <path>src/database/models.py</path>
        <kind>model</kind>
        <symbol>EnhancementHistory</symbol>
        <lines>106-189</lines>
        <reason>SQLAlchemy model for tracking enhancement history - fields: id, tenant_id, ticket_id, status, context_gathered, llm_output, error_message, processing_time_ms, created_at, completed_at</reason>
      </artifact>
      <artifact>
        <path>src/database/models.py</path>
        <kind>model</kind>
        <symbol>TenantConfig</symbol>
        <lines>referenced</lines>
        <reason>Tenant configuration model - contains base_url, api_key, tool_type for ServiceDesk Plus integration</reason>
      </artifact>
      <artifact>
        <path>src/utils/logger.py</path>
        <kind>utility</kind>
        <symbol>logger</symbol>
        <lines>entire-file</lines>
        <reason>Loguru logger configuration - used for structured logging with correlation IDs throughout pipeline</reason>
      </artifact>
      <artifact>
        <path>tests/integration/</path>
        <kind>test_directory</kind>
        <symbol>test_end_to_end_workflow.py</symbol>
        <lines>new-file</lines>
        <reason>Integration test file to be created for Story 2.11 - will contain 7 integration test scenarios</reason>
      </artifact>
    </code>
    <dependencies>
      <python>
        <package name="celery" version="5.x">Task queue and distributed task processing</package>
        <package name="redis" version="7.x">Message broker + caching layer</package>
        <package name="sqlalchemy" version="2.0+">Async ORM for database operations</package>
        <package name="asyncpg">Async PostgreSQL driver</package>
        <package name="langgraph" version="1.0+">AI workflow orchestration (Story 2.8)</package>
        <package name="openai">OpenAI SDK for OpenRouter API integration (Story 2.9)</package>
        <package name="httpx">Async HTTP client for API calls (Story 2.10)</package>
        <package name="loguru">Structured logging with correlation ID support</package>
        <package name="pydantic" version="2.x">Data validation and settings management</package>
        <package name="pytest">Testing framework</package>
        <package name="pytest-asyncio">Async test support</package>
        <package name="pytest-mock">Mocking support for tests</package>
      </python>
      <external_services>
        <service name="OpenRouter API">LLM synthesis via GPT-4o-mini - requires OPENROUTER_API_KEY env var</service>
        <service name="ServiceDesk Plus API">Ticket updates - requires tenant-specific base_url and api_key</service>
      </external_services>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint type="performance">NFR001: End-to-end latency target <60s p95, hard timeout 120s enforced at Celery task level</constraint>
    <constraint type="performance">Timeout budget allocation: Context gathering 30s + LLM synthesis 30s + API update 30s + overhead 30s = 120s total</constraint>
    <constraint type="reliability">NFR003: 99% reliability - graceful degradation required at every phase (partial context, LLM fallback, retry logic)</constraint>
    <constraint type="output">FR013: Enhancement output limited to maximum 500 words (enforced in Story 2.9 synthesize_enhancement function)</constraint>
    <constraint type="architecture">Async/await required throughout - Celery 5.x uses sync task wrapper with asyncio.run() for async operations</constraint>
    <constraint type="architecture">Never raise exceptions from API clients - Story 2.10 returns False on all failures (graceful degradation pattern)</constraint>
    <constraint type="logging">All operations must include correlation_id in structured logs for distributed tracing (NFR005)</constraint>
    <constraint type="database">EnhancementHistory records must ALWAYS be created (status='pending' at start, updated to 'completed'/'failed' on finish)</constraint>
    <constraint type="testing">Mock all external services (ServiceDesk Plus API, OpenRouter API) in integration tests to avoid flakiness</constraint>
    <constraint type="patterns">Maintain patterns from Stories 2.8-2.10: parallel execution, graceful degradation, retry with backoff, boolean returns (not exceptions)</constraint>
  </constraints>

  <interfaces>
    <interface>
      <name>execute_context_gathering</name>
      <kind>async function</kind>
      <signature>async def execute_context_gathering(tenant_id: str, ticket_id: str, description: str, priority: Optional[str], session: AsyncSession, kb_config: Dict, correlation_id: str) -> WorkflowState</signature>
      <path>src/workflows/enhancement_workflow.py:571-676</path>
      <description>LangGraph workflow executor - orchestrates parallel context gathering from Stories 2.5-2.7. Returns WorkflowState with similar_tickets, kb_articles, ip_info, errors, and timing metrics. Handles failed nodes gracefully (partial context acceptable).</description>
    </interface>
    <interface>
      <name>synthesize_enhancement</name>
      <kind>async function</kind>
      <signature>async def synthesize_enhancement(context: WorkflowState) -> str</signature>
      <path>src/services/llm_synthesis.py:247-418</path>
      <description>LLM synthesis using OpenRouter API + GPT-4o-mini. Accepts WorkflowState, returns markdown enhancement (max 500 words). Falls back to formatted context on failure. 30s timeout enforced. Token usage logged for cost tracking.</description>
    </interface>
    <interface>
      <name>update_ticket_with_enhancement</name>
      <kind>async function</kind>
      <signature>async def update_ticket_with_enhancement(base_url: str, api_key: str, ticket_id: str, enhancement: str) -> bool</signature>
      <path>src/services/servicedesk_client.py:194-347</path>
      <description>ServiceDesk Plus API client - posts enhancement as work note. Returns True on success, False on failure. Includes retry logic (3 attempts, exponential backoff 2s/4s/8s), markdown-to-HTML conversion, 30s timeout. Never raises exceptions (graceful degradation).</description>
    </interface>
    <interface>
      <name>WorkflowState</name>
      <kind>TypedDict class</kind>
      <signature>class WorkflowState(TypedDict): [fields: tenant_id, ticket_id, description, priority, timestamp, correlation_id, similar_tickets, kb_articles, ip_info, errors, timing metrics]</signature>
      <path>src/workflows/enhancement_workflow.py:53-94</path>
      <description>Complete state object passed through LangGraph workflow and to LLM synthesis. Contains gathered context, errors, and performance metrics. Used for both processing and audit logging.</description>
    </interface>
    <interface>
      <name>EnhancementHistory</name>
      <kind>SQLAlchemy model</kind>
      <signature>class EnhancementHistory(Base): [fields: id(UUID), tenant_id, ticket_id, status, context_gathered(JSON), llm_output, error_message, processing_time_ms, created_at, completed_at]</signature>
      <path>src/database/models.py:106-189</path>
      <description>Database model for tracking enhancement lifecycle. Created with status='pending' at task start, updated to 'completed' or 'failed' on finish. Stores full context_gathered and llm_output for debugging and analytics.</description>
    </interface>
    <interface>
      <name>enhance_ticket</name>
      <kind>Celery task (async)</kind>
      <signature>@celery_app.task(name="enhance_ticket", time_limit=120) async def enhance_ticket(payload: Dict) -> Dict</signature>
      <path>src/workers/tasks.py</path>
      <description>Main Celery task for Story 2.11 - orchestrates entire enhancement pipeline. Accepts payload with tenant_id, ticket_id, description, priority. Returns dict with status, enhancement_id, processing_time_ms. Enforces 120s hard timeout (NFR001).</description>
    </interface>
  </interfaces>
  <tests>
    <standards>
Project uses Pytest framework with pytest-asyncio for async test support. Testing standards:
- Unit tests: Test individual functions and classes in isolation with mocked dependencies
- Integration tests: Test component interactions with mocked external services (no real API calls)
- Mock external services: ServiceDesk Plus API and OpenRouter API must be mocked to avoid flakiness and cost
- Test structure: Arrange-Act-Assert pattern with clear test names (test_scenario_expected_behavior)
- Async tests: Use @pytest.mark.asyncio decorator, AsyncMock for async functions
- Coverage: Minimum 80% code coverage, 100% for critical paths (enhancement pipeline)
- Assertion patterns: Use assert statements, pytest.raises for exceptions, caplog for log verification
    </standards>
    <locations>
- tests/unit/: Unit tests for individual components (src/workers/tasks.py, src/services/*, src/workflows/*)
- tests/integration/: Integration tests for multi-component workflows
- tests/integration/test_end_to_end_workflow.py: Integration tests for Story 2.11 (NEW FILE - to be created)
- Existing test files: tests/unit/test_langgraph_workflow.py (Story 2.8), tests/unit/test_llm_synthesis.py (Story 2.9), tests/unit/test_servicedesk_client.py (Story 2.10)
    </locations>
    <ideas>
**AC1 - Complete Pipeline Functional:**
- Integration test: Full workflow from webhook payload to enhancement history record creation
- Mock: ServiceDesk Plus API (200 OK), OpenRouter API (valid response), DB operations
- Assert: enhancement_history record exists with status='completed', processing_time_ms logged

**AC2 - Celery Task Integration:**
- Unit test: enhance_ticket task signature and payload validation
- Unit test: Tenant config loading (success, failure, missing tenant)
- Unit test: Task orchestrates all phases in correct order (context → LLM → API → history update)

**AC3 - Enhancement History Recording:**
- Unit test: Record created with status='pending' at task start
- Unit test: Record updated to 'completed' on success with all fields populated
- Unit test: Record updated to 'failed' on error with error_message and correlation_id

**AC4 - Performance Requirements:**
- Integration test: Measure end-to-end latency, assert <60s for p95 scenarios
- Integration test: Verify 120s hard timeout enforced (mock slow operation, assert task fails at 120s)
- Unit test: Processing_time_ms calculation and logging

**AC5 - Error Handling and Graceful Degradation:**
- Integration test: Partial context failure (1 node fails, 2 succeed) → enhancement still completed
- Integration test: LLM synthesis failure → fallback formatting used, enhancement completed
- Integration test: ServiceDesk Plus API failure → status='failed', error_message logged

**AC6 - Logging with Correlation IDs:**
- Unit test: Correlation ID generated at task start (UUID format)
- Integration test: Correlation ID propagated through all components (grep logs for correlation_id)
- Unit test: All log statements include correlation_id in structured format

**AC7 - Integration Testing:**
- Integration test: Mock webhook payload → validate queue job → Celery task → all phases → history record
- Integration test: End-to-end latency measurement baseline (establish p50/p95/p99)
- Integration test: Multiple concurrent enhancements with different tenants (isolation verification)
    </ideas>
  </tests>
</story-context>
