<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>6</epicId>
    <storyId>7</storyId>
    <title>Add Worker Health and Resource Monitoring</title>
    <status>drafted</status>
    <generatedAt>2025-11-04</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/6-7-add-worker-health-and-resource-monitoring.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>an operations engineer</asA>
    <iWant>to view worker health and resource utilization</iWant>
    <soThat>I can identify performance bottlenecks and scale appropriately</soThat>
    <tasks>
      <task id="1" acs="#1, #3">Implement Celery Worker Discovery and Metadata Fetching - Use Celery inspect API (ping, stats, active) to discover workers and gather hostname, uptime, active/completed task counts, and determine worker status</task>
      <task id="2" acs="#2">Implement Worker Resource Utilization Metrics - Query Prometheus for worker-level CPU%, Memory%, and calculate task throughput (tasks/min) from metrics</task>
      <task id="3" acs="#1, #2, #3, #6">Create Workers Page with Worker List Table - Display worker data in interactive table with status indicators, alert threshold colors, and filters</task>
      <task id="4" acs="#4">Implement Worker Restart Functionality via Kubernetes API - Use kubernetes Python client to gracefully restart workers via deployment annotation patch</task>
      <task id="5" acs="#5">Implement Worker Logs Viewer - Use K8s CoreV1Api to fetch and display last 100 lines of worker logs with level filtering</task>
      <task id="6" acs="#7">Implement Historical Worker Performance Chart - Query Prometheus for 7-day throughput history and create Plotly chart with average line</task>
      <task id="7" acs="#8">Implement Auto-Refresh with Fragment - Wrap page in @st.fragment(run_every="30s") for automatic 30-second updates</task>
      <task id="8">Add Configuration and Dependencies - Update config.py, pyproject.toml, .env.example, and K8s RBAC manifests</task>
      <task id="9">Unit and Integration Testing - Comprehensive tests for all worker_helper.py functions with mocked external APIs</task>
    </tasks>
  </story>

  <acceptanceCriteria>
    <criterion id="1">Workers page displays list of active Celery workers (hostname, uptime, active tasks, completed tasks)</criterion>
    <criterion id="2">Resource utilization metrics per worker: CPU%, Memory%, Task throughput (tasks/min)</criterion>
    <criterion id="3">Worker status indicator (active/idle/unresponsive)</criterion>
    <criterion id="4">"Restart Worker" button for individual worker (sends TERM signal via K8s API)</criterion>
    <criterion id="5">Worker logs viewer (last 100 lines, filterable by log level)</criterion>
    <criterion id="6">Alert threshold indicators (CPU >80% = yellow, >95% = red)</criterion>
    <criterion id="7">Historical worker performance chart (last 7 days average throughput)</criterion>
    <criterion id="8">Data refreshed every 30 seconds</criterion>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/epics.md</path>
        <title>Epic 6: Admin UI & Configuration Management</title>
        <section>Story 6.7: Add Worker Health and Resource Monitoring</section>
        <snippet>Workers page displays active Celery workers with hostname, uptime, active/completed tasks, resource metrics (CPU%, Memory%, throughput), status indicators, restart controls, logs viewer, and historical performance charts with 30-second auto-refresh</snippet>
      </doc>
      <doc>
        <path>docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>FR031: Admin UI Worker Health Metrics</section>
        <snippet>Admin UI shall display worker health and resource utilization metrics to enable operations teams to monitor system capacity and identify performance bottlenecks</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>System Architecture</title>
        <section>Epic 6: Admin UI - Streamlit Framework</section>
        <snippet>Streamlit 1.30+ for web-based admin dashboard with Python-native components, shared SQLAlchemy database access, separate K8s service on port 8501. Includes Pandas for data manipulation and Plotly for interactive visualizations</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>System Architecture</title>
        <section>Observability Stack</section>
        <snippet>Prometheus for metrics collection, Celery 5.x distributed task queue, Redis 7.x message broker. Worker metrics instrumented in Epic 4.1 for monitoring CPU%, memory%, and task throughput</snippet>
      </doc>
      <doc>
        <path>docs/stories/6-6-integrate-real-time-metrics-display.md</path>
        <title>Story 6.6: Integrate Real-Time Metrics Display</title>
        <section>Foundation Components to Reuse</section>
        <snippet>fetch_prometheus_range_query() function in metrics_helper.py for querying Prometheus HTTP API with error resilience and caching. create_timeseries_chart() for Plotly graphs with downsampling. @st.fragment(run_every) pattern for auto-refresh</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/admin/utils/metrics_helper.py</path>
        <kind>helper</kind>
        <symbol>fetch_prometheus_range_query</symbol>
        <lines>333-414</lines>
        <reason>REUSE this function for querying Prometheus HTTP API with time-series data for worker throughput history (AC#7). Returns tuple (data, unavailable_flag) with error resilience and session state caching</reason>
      </artifact>
      <artifact>
        <path>src/admin/utils/metrics_helper.py</path>
        <kind>helper</kind>
        <symbol>create_timeseries_chart</symbol>
        <lines>589-647</lines>
        <reason>REUSE this function as base for creating historical worker performance charts (AC#7). Provides Plotly graph_objects with hover tooltips, zoom, pan, and downsampling for >1000 points</reason>
      </artifact>
      <artifact>
        <path>src/admin/pages/1_Dashboard.py</path>
        <kind>page</kind>
        <symbol>@st.fragment(run_every="60s")</symbol>
        <lines>267</lines>
        <reason>Pattern for implementing 30-second auto-refresh (AC#8). Use same decorator pattern but with run_every="30s" parameter</reason>
      </artifact>
      <artifact>
        <path>src/workers/celery_app.py</path>
        <kind>service</kind>
        <symbol>celery_app</symbol>
        <lines>1-100</lines>
        <reason>Celery app instance for worker discovery. Use celery_app.control.inspect() API to discover active workers, fetch stats, and check worker health</reason>
      </artifact>
      <artifact>
        <path>src/config.py</path>
        <kind>config</kind>
        <symbol>Settings</symbol>
        <lines>28-195</lines>
        <reason>Add new configuration fields: celery_app_name (for Celery app import), kubernetes_namespace, kubernetes_in_cluster, worker_log_lines. Follow existing Field() pattern with env parameter</reason>
      </artifact>
      <artifact>
        <path>src/admin/utils/db_helper.py</path>
        <kind>helper</kind>
        <symbol>get_db_engine</symbol>
        <lines></lines>
        <reason>Pattern for creating connection pools with @st.cache_resource. Follow same pattern for Celery app factory function</reason>
      </artifact>
      <artifact>
        <path>k8s/streamlit-admin-deployment.yaml</path>
        <kind>k8s-manifest</kind>
        <symbol>Deployment</symbol>
        <lines></lines>
        <reason>Add serviceAccountName field to enable Streamlit pod to access Kubernetes API for worker restart and logs viewing (AC#4, AC#5)</reason>
      </artifact>
    </code>
    <dependencies>
      <python>
        <package name="celery" version=">=5.3.4" usage="Worker discovery via control.inspect() API, already installed"/>
        <package name="kubernetes" version="latest" usage="K8s API client for worker restart (AC#4) and logs viewing (AC#5), NEEDS TO BE ADDED"/>
        <package name="psutil" version="latest" usage="Optional: Direct process CPU/Memory monitoring if Prometheus metrics unavailable, CHECK IF ALREADY INSTALLED"/>
        <package name="streamlit" version=">=1.44.0" usage="Admin UI framework with @st.fragment auto-refresh, already installed"/>
        <package name="pandas" version=">=2.1.0" usage="Data manipulation for worker list table, already installed"/>
        <package name="plotly" version=">=5.18.0" usage="Interactive performance charts, already installed"/>
        <package name="httpx" version=">=0.25.2" usage="HTTP client for Prometheus API calls, already installed"/>
        <package name="prometheus-client" version=">=0.19.0" usage="Metrics instrumentation (Epic 4.1), already installed"/>
      </python>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint id="C1">Create NEW worker_helper.py file - DO NOT add functions to metrics_helper.py (already at 647 lines, 29% over 500-line limit per CLAUDE.md)</constraint>
    <constraint id="C2">REUSE existing functions: fetch_prometheus_range_query() and create_timeseries_chart() from metrics_helper.py - DO NOT recreate these</constraint>
    <constraint id="C3">Follow Story 6.6 patterns: httpx for HTTP, @st.cache_resource for connections, @st.cache_data(ttl=N) for queries, session state for caching fallback</constraint>
    <constraint id="C4">All functions require type hints and Google-style docstrings per project conventions</constraint>
    <constraint id="C5">Use PEP8 compliance with Black formatter (line length 100)</constraint>
    <constraint id="C6">Page numbering: Check existing pages directory - may be 5_Workers.py if another page added since Story 6.5</constraint>
    <constraint id="C7">Kubernetes RBAC required: Create k8s/streamlit-rbac.yaml with ServiceAccount, Role (pod list/delete/logs, deployment patch), RoleBinding</constraint>
    <constraint id="C8">Use datetime.now(datetime.UTC) NOT datetime.utcnow() (deprecated in Python 3.12+)</constraint>
    <constraint id="C9">Synchronous operations only (Streamlit compatibility) - no async/await in Streamlit pages</constraint>
    <constraint id="C10">Error resilience: All external API calls (Celery, Prometheus, K8s) must handle connection errors gracefully with logged warnings and fallback values</constraint>
  </constraints>
  <interfaces>
    <interface>
      <name>Celery Control Inspect API</name>
      <kind>Python API</kind>
      <signature>celery_app.control.inspect().ping() -> dict[str, dict]
celery_app.control.inspect().stats() -> dict[str, dict]
celery_app.control.inspect().active() -> dict[str, list]</signature>
      <path>src/workers/celery_app.py</path>
      <usage>Worker discovery and metadata fetching (Task 1, AC#1, #3)</usage>
    </interface>
    <interface>
      <name>Prometheus HTTP API</name>
      <kind>REST endpoint</kind>
      <signature>GET {prometheus_url}/api/v1/query_range?query={promql}&start={unix_ts}&end={unix_ts}&step={duration}</signature>
      <path>src/admin/utils/metrics_helper.py:fetch_prometheus_range_query</path>
      <usage>Query worker-level metrics (CPU%, Memory%, throughput) and 7-day historical data (Task 2, Task 6, AC#2, #7)</usage>
    </interface>
    <interface>
      <name>Kubernetes CoreV1Api</name>
      <kind>Python API</kind>
      <signature>v1.list_namespaced_pod(namespace, label_selector) -> V1PodList
v1.read_namespaced_pod_log(name, namespace, tail_lines, timestamps) -> str
v1.delete_namespaced_pod(name, namespace) -> V1Status</signature>
      <path>kubernetes Python client library</path>
      <usage>Worker logs viewing and pod operations (Task 5, AC#5)</usage>
    </interface>
    <interface>
      <name>Kubernetes AppsV1Api</name>
      <kind>Python API</kind>
      <signature>apps_v1.patch_namespaced_deployment(name, namespace, body) -> V1Deployment</signature>
      <path>kubernetes Python client library</path>
      <usage>Graceful worker restart via deployment annotation patch (Task 4, AC#4)</usage>
    </interface>
    <interface>
      <name>Streamlit Fragment Decorator</name>
      <kind>Decorator</kind>
      <signature>@st.fragment(run_every="30s")
def display_workers_page(): ...</signature>
      <path>streamlit library</path>
      <usage>30-second auto-refresh without full page reload (Task 7, AC#8)</usage>
    </interface>
  </interfaces>
  <tests>
    <standards>Pytest framework with comprehensive mocking for external APIs. All functions require unit tests following pattern: 1 expected use case, 1 edge case, 1 failure case. Mock external dependencies: celery.control.inspect(), httpx responses for Prometheus, kubernetes API clients, streamlit components. Use @pytest.fixture(autouse=True) for cache clearing. Integration tests optional for real service validation. Tests follow Google-style docstrings and type hints. Story 6.6 test_metrics_prometheus.py provides reference patterns for mocking Prometheus API and Streamlit components.</standards>
    <locations>tests/admin/test_worker_helper.py (new file for worker monitoring functions), tests/ directory mirrors src/ structure</locations>
    <ideas>
      <test ac="1,3">Test fetch_celery_workers() with mocked inspect API: verify ping/stats/active calls, test active/idle/unresponsive status determination, test connection error handling returning empty list</test>
      <test ac="2">Test fetch_worker_resources() with mocked Prometheus responses: verify CPU/Memory/Throughput queries, test throughput calculation from delta, test Prometheus unavailable fallback</test>
      <test ac="4">Test restart_worker_k8s() with mocked K8s API: verify deployment patch call with annotation, test permission errors (403), test pod not found scenarios</test>
      <test ac="5">Test fetch_worker_logs() with mocked K8s logs API: verify log retrieval with tail_lines parameter, test log level filtering (ERROR, WARNING, INFO), test pod not found graceful handling</test>
      <test ac="7">Test fetch_worker_throughput_history() with mocked Prometheus time-series: verify 7-day query with 1h step, test data parsing to list of dicts</test>
      <test ac="7">Test create_worker_performance_chart() with sample data: verify Plotly figure creation, verify average line annotation present</test>
      <test>Integration test: Start local Celery worker, query real data through all functions, verify end-to-end workflow</test>
      <test>Manual UI test: Launch Streamlit app, verify Workers page displays, test filters, restart button confirmation, logs viewer, charts, auto-refresh behavior</test>
    </ideas>
  </tests>
</story-context>
