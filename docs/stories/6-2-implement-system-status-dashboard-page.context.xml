<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>6</epicId>
    <storyId>2</storyId>
    <title>Implement System Status Dashboard Page</title>
    <status>drafted</status>
    <generatedAt>2025-11-04</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/6-2-implement-system-status-dashboard-page.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>an operations manager</asA>
    <iWant>to see real-time system status and key metrics</iWant>
    <soThat>I can quickly assess system health at a glance</soThat>
    <tasks>
### Task 1: Implement System Status Indicator (AC: #1, #7)
- Create status calculation logic in src/admin/utils/status_helper.py
- Implement health check function: get_system_status() returns "Healthy", "Degraded", or "Down"
- Status logic: Down = no database/Redis connection, Degraded = success rate < 80% OR queue depth > 100, Healthy = all checks pass
- Use st.status() widget for status display with color coding (green=healthy, yellow=degraded, red=down)
- Add status icon emoji: ✅ Healthy, ⚠️ Degraded, ❌ Down
- Test status transitions: mock connection failures, low success rate scenarios
- Add unit tests for get_system_status() with various health conditions

### Task 2: Display Key Metrics with st.metric (AC: #2)
- Create metrics query helper in src/admin/utils/metrics_helper.py
- Implement get_queue_depth() using Redis llen() command on "celery" queue
- Implement get_success_rate_24h() querying enhancement_history table
- Implement get_p95_latency() querying enhancement_history table
- Implement get_active_workers() using Celery inspect().active() or Prometheus
- Display metrics using st.columns(4) and st.metric() with delta indicators (vs 1h ago)
- Format metrics: Queue depth (integer), Success rate (percentage), P95 latency (ms), Active workers (integer)
- Add @st.cache_data(ttl=30) decorator to metrics functions for performance
- Test metrics display with mock data and verify delta calculations

### Task 3: Show Recent Failures Section (AC: #3)
- Create get_recent_failures() function in src/admin/utils/metrics_helper.py
- Query enhancement_history: SELECT ticket_id, tenant_id, error_message, created_at FROM enhancement_history WHERE status='failed' ORDER BY created_at DESC LIMIT 10
- Display failures using st.expander("Recent Failures (Last 10)", expanded=False)
- Format each failure as table row: Ticket ID | Tenant | Error | Timestamp
- Truncate long error messages (max 100 chars, show "..." with hover tooltip for full message)
- Add st.empty() placeholder when no recent failures
- Color-code failure rows with light red background using st.markdown custom CSS
- Test with mock failure data and verify sorting by timestamp

### Task 4: Display Connection Status Indicators (AC: #4, #5)
- Reuse test_database_connection() from src/admin/utils/db_helper.py for PostgreSQL status
- Create test_redis_connection() function in src/admin/utils/redis_helper.py
- Implement Redis ping() command with 2-second timeout for connection check
- Display connection statuses using st.columns(2) with st.metric or st.status
- Show green checkmark ✅ for connected, red X ❌ for disconnected
- Include connection response time in status display
- Add error handling: connection failures show error message without crashing dashboard
- Test connection status with mock Redis/PostgreSQL unavailability scenarios

### Task 5: Implement Auto-Refresh with Streamlit Fragment (AC: #6)
- Use Streamlit @st.fragment(run_every=30) decorator for auto-refresh (2025 best practice)
- Create dashboard_fragment() function wrapping all metrics and status displays
- Add refresh interval selector in sidebar
- Store refresh interval in st.session_state["refresh_interval"]
- Add manual refresh button: st.button("Refresh Now") triggers st.rerun()
- Display last refresh timestamp
- Add toggle button "Pause Auto-Refresh" to disable fragment auto-rerun
- Test auto-refresh: verify dashboard updates every 30s without full page reload

### Task 6: Optimize Dashboard Performance (AC: #8)
- Use @st.cache_data(ttl=30) on all database query functions
- Implement connection pooling for database queries
- Add SQL query indexes on enhancement_history: (status, created_at), (status, completed_at)
- Limit query results: use LIMIT clauses
- Use st.spinner("Loading dashboard...") during data fetch operations
- Measure load time using time.time() before/after data fetch, log if > 2 seconds
- Profile dashboard rendering with Streamlit profiler
- Test performance with large datasets (10K+ enhancement history records)

### Task 7: Add Prometheus Integration for Metrics (Optional Enhancement)
- Research Prometheus HTTP API client libraries
- Install prometheus-api-client: add to pyproject.toml dependencies
- Create src/admin/utils/prometheus_helper.py with PrometheusClient class
- Implement query_instant(query: str) method using /api/v1/query endpoint
- Implement query_range(query: str, start: datetime, end: datetime) for time-series data
- Add Prometheus server URL to .streamlit/secrets.toml
- Fallback logic: if Prometheus unavailable, use database queries from Task 2
- Test Prometheus queries

### Task 8: Testing and Validation (Meta)
- Create tests/admin/test_status_helper.py for system status calculation logic
- Create tests/admin/test_metrics_helper.py for metrics query functions
- Create tests/admin/test_redis_helper.py for Redis connection testing
- Test dashboard page initialization: verify all metrics render without errors
- Test auto-refresh behavior: mock time progression, verify fragment reruns every 30s
- Manual test: launch app, open dashboard, verify metrics update in real-time
- Load test: simulate 100 concurrent dashboard viewers, measure response time
- Code review checklist: PEP8 compliance, type hints, docstrings, error handling
    </tasks>
  </story>

  <acceptanceCriteria>
1. Dashboard page displays system status indicator (Healthy/Degraded/Down)
2. Key metrics displayed with st.metric: Queue depth, Success rate (24h), P95 latency, Active workers
3. Recent failures shown in expandable section (last 10 failed enhancements with error messages)
4. Redis connection status displayed
5. PostgreSQL connection status displayed
6. Auto-refresh implemented (configurable interval, default 30s)
7. Visual indicators use color coding (green=healthy, yellow=warning, red=critical)
8. Load time < 2 seconds for dashboard
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>FR027 - Admin UI Dashboard Requirements</section>
        <snippet>FR027: Admin UI shall display real-time system status dashboard with key metrics (queue depth, success rate, active workers). FR028: Admin UI shall provide tenant management interface for CRUD operations on tenant configurations.</snippet>
      </doc>
      <doc>
        <path>docs/epics.md</path>
        <title>Epic Definitions</title>
        <section>Epic 6: Admin UI & Configuration Management - Story 6.2</section>
        <snippet>Story 6.2: Implement System Status Dashboard Page - Operations manager wants to see real-time system status and key metrics. Prerequisites: Story 6.1 (Streamlit foundation), Story 4.1 (Prometheus metrics available). Acceptance criteria include system status indicator (Healthy/Degraded/Down), key metrics with st.metric, recent failures section, connection status for Redis and PostgreSQL, auto-refresh with configurable interval, color coding, and load time < 2 seconds.</snippet>
      </doc>
      <doc>
        <path>docs/operations/metrics-guide.md</path>
        <title>Prometheus Metrics Guide</title>
        <section>Available Metrics and PromQL Queries</section>
        <snippet>Defines 5 Prometheus metrics: enhancement_requests_total (Counter with tenant_id, status labels), enhancement_duration_seconds (Histogram for latency analysis), enhancement_success_rate (Gauge 0-100%), queue_depth (Gauge with queue_name label), worker_active_count (Gauge with worker_type label). Sample PromQL: histogram_quantile(0.95, rate(enhancement_duration_seconds_bucket[5m])) for p95 latency.</snippet>
      </doc>
      <doc>
        <path>docs/stories/6-1-set-up-streamlit-application-foundation.md</path>
        <title>Story 6.1 Foundation - Completion Notes</title>
        <section>Dev Agent Record - Implementation Summary and Learnings</section>
        <snippet>Foundation complete with src/admin/ module structure, db_helper.py provides synchronous SQLAlchemy connection (@st.cache_resource for pooling), multi-page navigation configured (1_Dashboard.py, 2_Tenants.py, 3_History.py), dual-mode authentication (session state for local, K8s Ingress basic auth for production), Kubernetes manifests deployed (deployment, service, ingress, configmap), 38 tests passing (100% pass rate). Key decision: Separate db_helper.py with psycopg2-binary for Streamlit (asyncpg incompatible with sync execution model). Dashboard page ready at src/admin/pages/1_Dashboard.py (skeleton, 75 lines).</snippet>
      </doc>
      <doc>
        <path>Ref MCP - Streamlit Fragments Documentation</path>
        <title>Streamlit Fragments for Auto-Refresh (2025)</title>
        <section>Automate Fragment Reruns</section>
        <snippet>@st.fragment(run_every="10s") decorator causes fragment to rerun automatically at specified interval. Reruns continue even without user interaction. Great for live data streams or status monitoring. Example: @st.fragment(run_every="10s") def auto_function(): df = get_latest_updates(); st.line_chart(df). Official recommended pattern for dashboards in Streamlit 1.44+.</snippet>
      </doc>
      <doc>
        <path>Ref MCP - Streamlit Caching Documentation</path>
        <title>Streamlit Caching with st.cache_data (2025)</title>
        <section>Caching Overview and TTL Parameter</section>
        <snippet>@st.cache_data is recommended for caching data computations (DataFrames, API calls, database queries). Creates copy via serialization to prevent mutation. ttl parameter sets time-to-live for cache expiration. Example: @st.cache_data(ttl=3600) for 1 hour cache. Always use ttl for database/API queries to avoid stale data. max_entries parameter limits cache size. show_spinner parameter customizes loading indicator.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/admin/utils/db_helper.py</path>
        <kind>database utility module</kind>
        <symbol>get_db_session</symbol>
        <lines>99-136</lines>
        <reason>Context manager for database sessions with automatic commit/rollback. Must reuse this for all database queries in dashboard metrics.</reason>
      </artifact>
      <artifact>
        <path>src/admin/utils/db_helper.py</path>
        <kind>database utility module</kind>
        <symbol>test_database_connection</symbol>
        <lines>157-188</lines>
        <reason>Returns (bool, str) tuple for database connection status. Reuse for PostgreSQL connection status display (AC#5).</reason>
      </artifact>
      <artifact>
        <path>src/database/models.py</path>
        <kind>database model</kind>
        <symbol>EnhancementHistory</symbol>
        <lines>112-195</lines>
        <reason>Table schema for enhancement_history. Fields: id (UUID), tenant_id, ticket_id, status (pending/completed/failed), error_message, processing_time_ms, created_at, completed_at. Query this table for success rate, P95 latency, and recent failures metrics.</reason>
      </artifact>
      <artifact>
        <path>src/monitoring/metrics.py</path>
        <kind>prometheus metrics definitions</kind>
        <symbol>enhancement_requests_total, enhancement_duration_seconds, enhancement_success_rate, queue_depth, worker_active_count</symbol>
        <lines>N/A</lines>
        <reason>Five Prometheus metrics exposed at /metrics endpoint. Optional Task 7 can query these via Prometheus HTTP API as alternative to database queries for better performance.</reason>
      </artifact>
      <artifact>
        <path>src/cache/redis_client.py</path>
        <kind>redis utility module</kind>
        <symbol>get_redis_client</symbol>
        <lines>18-40</lines>
        <reason>Async Redis client with connection pooling. Note: This is async, but Streamlit requires sync operations. Story 6.2 needs to create sync Redis client for connection testing and queue depth queries (Task 4). Use redis.Redis.from_url() with decode_responses=True for sync operations.</reason>
      </artifact>
      <artifact>
        <path>src/admin/pages/1_Dashboard.py</path>
        <kind>streamlit page skeleton</kind>
        <symbol>show</symbol>
        <lines>1-75</lines>
        <reason>Current skeleton implementation with placeholder metrics. Replace placeholders with real implementations in Story 6.2. Already imports show_connection_status from admin.utils.</reason>
      </artifact>
    </code>
    <dependencies>
      <python>
        <runtime_version>Python 3.12</runtime_version>
        <package_manager>uv (pyproject.toml)</package_manager>
        <core_dependencies>
          <package name="streamlit" version=">=1.44.0" status="already installed">
            Multi-page apps with st.Page and st.navigation.
            @st.fragment(run_every=N) for auto-refresh (AC#6).
            @st.cache_data(ttl=30) for database query caching.
            @st.cache_resource for connection pooling.
            st.metric for KPI display (AC#2).
            st.status for health indicators (AC#1, AC#7).
          </package>
          <package name="redis" version=">=5.0.1" status="already installed">
            Sync Redis client (redis.Redis.from_url) for connection testing and queue depth.
            Commands: ping() for health check (AC#4), llen("celery") for queue depth (AC#2).
            Note: Existing src/cache/redis_client.py is async, create sync client in redis_helper.py.
          </package>
          <package name="sqlalchemy" version=">=2.0.23" status="already installed">
            Database ORM for querying enhancement_history table.
            Use with psycopg2-binary driver (sync mode for Streamlit).
            Query patterns: session.query(EnhancementHistory).filter(...).all()
          </package>
          <package name="psycopg2-binary" version=">=2.9.9" status="already installed">
            Sync PostgreSQL driver for Streamlit (asyncpg incompatible with Streamlit's sync model).
            Already configured in db_helper.py with connection pooling.
          </package>
          <package name="pandas" version=">=2.1.0" status="already installed">
            Optional for data manipulation and filtering if needed.
            Useful for recent failures table formatting (Task 3).
          </package>
          <package name="celery" version=">=5.3.4" status="already installed">
            Optional for Task 2.5: celery.task.control.inspect().active() to get active worker count.
            Alternative: Query worker_active_count gauge from Prometheus (Task 7).
          </package>
        </core_dependencies>
        <optional_dependencies>
          <package name="prometheus-api-client" version=">=0.5.3" status="not installed">
            Task 7 optional enhancement - Query Prometheus HTTP API for metrics.
            Methods: custom_query(promql_string) for instant queries.
            Provides better performance than database queries for time-series data.
            If added, update pyproject.toml dependencies list.
          </package>
        </optional_dependencies>
        <dev_dependencies>
          <package name="pytest" version=">=7.4.3" status="already installed">Unit test framework</package>
          <package name="pytest-mock" version=">=3.12.0" status="already installed">Mocking for Streamlit components</package>
          <package name="black" version=">=23.11.0" status="already installed">Code formatter (line length 100)</package>
        </dev_dependencies>
      </python>
      <frameworks>
        <framework name="Streamlit" version="1.44+">
          Web-based admin UI framework with reactive updates and auto-refresh capabilities.
        </framework>
        <framework name="SQLAlchemy" version="2.0.23+">
          ORM for database queries (enhancement_history table).
        </framework>
        <framework name="Prometheus" version="N/A">
          Optional metrics backend (Task 7). Metrics already instrumented in src/monitoring/metrics.py.
        </framework>
      </frameworks>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint id="C1">All files must be under 500 lines (CLAUDE.md requirement). If helper modules exceed this, split into separate files.</constraint>
    <constraint id="C2">Use synchronous operations only - Streamlit execution model is synchronous. Cannot use async/await in Streamlit pages or cached functions.</constraint>
    <constraint id="C3">Reuse existing database connection pattern from db_helper.py. Use @st.cache_resource for connection pooling, @st.cache_data(ttl=30) for queries.</constraint>
    <constraint id="C4">Follow Story 6.1 patterns: Google-style docstrings, type hints on all functions, PEP8 compliance (Black formatter, line length 100).</constraint>
    <constraint id="C5">Database queries must use project-relative paths only in context file. Strip /Users/ravi/Documents/nullBytes_Apps/Ai_Agents/AI Ops prefix.</constraint>
    <constraint id="C6">Performance target: Dashboard load time < 2 seconds (AC#8). Use query limits (LIMIT 10), indexes on (status, created_at), connection pooling.</constraint>
    <constraint id="C7">Auto-refresh implementation must use @st.fragment(run_every=30) decorator (Streamlit 1.44+ official pattern, not third-party components).</constraint>
    <constraint id="C8">Environment variables: AI_AGENTS_DATABASE_URL for PostgreSQL, AI_AGENTS_REDIS_URL for Redis (from .env.example). Connection strings use service names (postgres, redis) in Docker, localhost for local dev.</constraint>
    <constraint id="C9">Redis Celery queue name is "celery" (database 1). Use llen("celery") command for queue depth. Cache is on database 0.</constraint>
    <constraint id="C10">Test coverage required: pytest unit tests for all helper functions (status_helper.py, metrics_helper.py, redis_helper.py). Follow Story 6.1 testing patterns with pytest-mock.</constraint>
  </constraints>
  <interfaces>
    <interface>
      <name>EnhancementHistory Table Schema</name>
      <kind>database table</kind>
      <signature>
        Columns: id (UUID), tenant_id (String(100)), ticket_id (String(100)),
        status (String(50): 'pending', 'completed', 'failed'),
        context_gathered (JSON), llm_output (Text), error_message (Text),
        processing_time_ms (Integer), created_at (DateTime), completed_at (DateTime)

        Indexes: (tenant_id, ticket_id), (status, created_at) - ADD NEW INDEX FOR AC#8 performance
      </signature>
      <path>src/database/models.py</path>
    </interface>
    <interface>
      <name>get_db_session Context Manager</name>
      <kind>database utility function</kind>
      <signature>
        @contextmanager
        def get_db_session() -> Generator[Session, None, None]:
            """Yields SQLAlchemy session with auto commit/rollback"""
      </signature>
      <path>src/admin/utils/db_helper.py</path>
    </interface>
    <interface>
      <name>test_database_connection</name>
      <kind>database utility function</kind>
      <signature>
        def test_database_connection() -> tuple[bool, str]:
            """Returns (success: bool, message: str) for connection status"""
      </signature>
      <path>src/admin/utils/db_helper.py</path>
    </interface>
    <interface>
      <name>Redis Connection (Sync)</name>
      <kind>redis client</kind>
      <signature>
        import redis
        client = redis.Redis.from_url(
            AI_AGENTS_REDIS_URL,
            decode_responses=True,
            socket_connect_timeout=2
        )
        queue_depth = client.llen("celery")  # Queue depth query
        client.ping()  # Connection test
      </signature>
      <path>Create new: src/admin/utils/redis_helper.py</path>
    </interface>
    <interface>
      <name>Prometheus HTTP API (Optional - Task 7)</name>
      <kind>REST API</kind>
      <signature>
        GET http://prometheus:9090/api/v1/query?query=queue_depth
        Response: {"status": "success", "data": {"resultType": "vector", "result": [{"metric": {...}, "value": [timestamp, "value"]}]}}
      </signature>
      <path>External service, query via prometheus-api-client library</path>
    </interface>
  </interfaces>
  <tests>
    <standards>
Testing framework: pytest with pytest-mock for Streamlit component mocking. Test file naming: test_*.py. All test files in tests/admin/ directory mirroring src/admin/ structure. Use @pytest.fixture(autouse=True) with st.cache_resource.clear() to prevent cached results across tests. Mock Streamlit components (st.metric, st.columns, st.expander, etc.) using pytest-mock. Use MagicMock for SQLAlchemy sessions and Redis clients. Test coverage targets: all helper functions (status_helper.py, metrics_helper.py, redis_helper.py) with unit tests for success, edge cases, and failure scenarios. Integration tests verify dashboard page renders without errors. Follow Story 6.1 patterns: clear_streamlit_cache fixture, mock environment variables with patch.dict, mock database/Redis connections to avoid external dependencies. Code quality: PEP8 compliance (Black), type hints, Google-style docstrings on test functions.
    </standards>
    <locations>
      <location>tests/admin/test_status_helper.py</location>
      <location>tests/admin/test_metrics_helper.py</location>
      <location>tests/admin/test_redis_helper.py</location>
      <location>tests/admin/test_dashboard_page.py</location>
    </locations>
    <ideas>
      <test_idea ac="AC1, AC7">
        Test get_system_status() function with various health scenarios:
        - Test healthy state: all connections up, success rate 95%, queue depth 50
        - Test degraded state: success rate 75% (below 80% threshold)
        - Test degraded state: queue depth 150 (above 100 threshold)
        - Test down state: database connection failure
        - Test down state: Redis connection failure
        - Verify correct status returned: "Healthy", "Degraded", "Down"
        - Verify emoji icons: ✅, ⚠️, ❌
      </test_idea>
      <test_idea ac="AC2">
        Test metrics query functions:
        - test_get_queue_depth(): Mock Redis llen() response, verify integer returned
        - test_get_success_rate_24h(): Mock SQLAlchemy query, verify percentage calculation (completed / total * 100)
        - test_get_p95_latency(): Mock percentile query, verify milliseconds returned
        - test_get_active_workers(): Mock Celery inspect or Prometheus query, verify integer count
        - Test delta calculations: mock "1 hour ago" data, verify delta computed correctly
        - Test cache decorator: verify @st.cache_data(ttl=30) applied, function not re-executed on second call
      </test_idea>
      <test_idea ac="AC3">
        Test get_recent_failures() function:
        - Mock enhancement_history query returning 10 failed records
        - Verify ORDER BY created_at DESC LIMIT 10 applied
        - Verify fields extracted: ticket_id, tenant_id, error_message, created_at
        - Test error message truncation: mock 200-char error, verify 100-char limit with "..."
        - Test empty failures: mock empty result, verify empty list returned
      </test_idea>
      <test_idea ac="AC4, AC5">
        Test connection status functions:
        - test_redis_connection(): Mock redis.ping() success, verify (True, "✅ Connected") tuple
        - test_redis_connection_failure(): Mock redis.ping() timeout, verify (False, "❌ Failed") tuple
        - test_database_connection(): Reuse existing test from test_db_helper.py, verify tuple format
        - Test connection response time: mock ping with 12ms latency, verify included in message
      </test_idea>
      <test_idea ac="AC6">
        Test auto-refresh fragment:
        - Mock @st.fragment(run_every=30) decorator, verify applied to dashboard_metrics() function
        - Test refresh interval selector: mock st.selectbox, verify st.session_state["refresh_interval"] updated
        - Test manual refresh button: mock st.button click, verify st.rerun() called
        - Test pause auto-refresh: mock toggle button, verify fragment not rerun when paused
        - Test last refresh timestamp: verify datetime.now() displayed in correct format
      </test_idea>
      <test_idea ac="AC8">
        Test dashboard performance:
        - Mock all database queries with instant responses, measure total render time
        - Verify @st.cache_data(ttl=30) applied to all query functions
        - Test connection pooling: verify get_db_session() reuses existing engine
        - Mock large dataset (10K enhancement history records), verify LIMIT 10 applied
        - Test query indexes: verify queries use (status, created_at) index
      </test_idea>
      <test_idea ac="Meta - Task 8">
        Integration test for full dashboard page:
        - Mock all external dependencies (database, Redis, Prometheus)
        - Call dashboard show() function
        - Verify no exceptions raised
        - Verify st.metric called 4 times (queue depth, success rate, P95 latency, active workers)
        - Verify st.status called once (system health)
        - Verify st.expander called for recent failures section
        - Verify connection status indicators displayed (PostgreSQL, Redis)
      </test_idea>
    </ideas>
  </tests>
</story-context>
