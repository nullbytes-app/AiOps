<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>2.8</storyId>
    <title>Integrate LangGraph Workflow Orchestration</title>
    <status>drafted</status>
    <generatedAt>2025-11-02</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/2-8-integrate-langgraph-workflow-orchestration.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>an enhancement agent</asA>
    <iWant>to orchestrate context gathering using LangGraph</iWant>
    <soThat>searches run concurrently and results are combined efficiently</soThat>
    <tasks>
- Task 1: Design LangGraph workflow structure (AC: #1, #2, #3)
- Task 2: Implement ticket history search node (AC: #1)
- Task 3: Implement knowledge base search node (AC: #1)
- Task 4: Implement IP lookup node (AC: #1)
- Task 5: Implement aggregation node (AC: #3)
- Task 6: Configure LangGraph workflow (AC: #1, #2, #3)
- Task 7: Implement error handling and graceful degradation (AC: #4)
- Task 8: Add workflow state persistence for debugging (AC: #5)
- Task 9: Implement performance logging (AC: #6)
- Task 10: Create unit tests for workflow (AC: #7)
- Task 11: Integration test with mock Celery task (AC: #7)
- Task 12: Document workflow architecture and API contract (AC: #1, #3)
- Task 13: Verify integration with Story 2.5, 2.6, 2.7 services (AC: #1, #2)
- Task 14: Performance testing and optimization (AC: #2, #6)
    </tasks>
  </story>

  <acceptanceCriteria>
1. LangGraph workflow defined with nodes: ticket_search, doc_search, ip_search
2. Nodes execute concurrently for performance
3. Workflow aggregates results from all nodes
4. Failed nodes don't block workflow (partial results acceptable)
5. Workflow state persisted for debugging
6. Workflow execution time logged
7. Unit tests verify concurrent execution and result aggregation
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/tech-spec-epic-2.md</path>
        <title>Epic Technical Specification: Core Enhancement Agent</title>
        <section>Section 6: Workflow Orchestration - LangGraph Integration (Story 2.8)</section>
        <snippet>LangGraph workflow orchestrates context gathering nodes (ticket_search, kb_search, ip_lookup) in parallel using StateGraph. Nodes execute concurrently, then aggregate results. Reduces latency from ~30s sequential to ~10-15s parallel with graceful degradation for failed nodes.</snippet>
      </doc>
      <doc>
        <path>docs/tech-spec-epic-2.md</path>
        <title>Epic Technical Specification: Core Enhancement Agent</title>
        <section>System Architecture Alignment - Epic 2 Architecture Diagram</section>
        <snippet>Story 2.8 LangGraph Orchestration executes parallel nodes: ticket_search_node (Story 2.5), doc_search_node (Story 2.6), ip_lookup_node (Story 2.7). All context fed to aggregate_results_node before passing to Story 2.9 synthesis.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>AI Agents - Decision Architecture</title>
        <section>Decision Summary - AI Orchestration</section>
        <snippet>LangGraph 1.0+ selected for AI orchestration. Provides concurrent workflow execution, state management, production-ready v1.0 released Sept 2025. Supports parallel node execution pattern essential for performance.</snippet>
      </doc>
      <doc>
        <path>docs/PRD.md</path>
        <title>AI Agents Product Requirements Document</title>
        <section>Functional Requirements - FR010</section>
        <snippet>System shall use LangGraph workflow to orchestrate concurrent context gathering operations. Essential for performance and scalability.</snippet>
      </doc>
      <doc>
        <path>docs/stories/2-5-implement-ticket-history-search-context-gathering.md</path>
        <title>Story 2.5: Implement Ticket History Search</title>
        <section>Story and Acceptance Criteria</section>
        <snippet>Search function returns top 5 similar tickets with ticket_id, description, resolution, resolved_date. Uses PostgreSQL full-text search, filters by tenant_id. Status: done.</snippet>
      </doc>
      <doc>
        <path>docs/stories/2-6-implement-documentation-and-knowledge-base-search.md</path>
        <title>Story 2.6: Implement Documentation and Knowledge Base Search</title>
        <section>Story and Acceptance Criteria</section>
        <snippet>Search function returns top 3 KB articles with title, summary, URL. Uses Redis caching (1hr TTL), 10s timeout, graceful degradation on API unavailability. Status: done.</snippet>
      </doc>
      <doc>
        <path>docs/stories/2-7-implement-ip-address-cross-reference.md</path>
        <title>Story 2.7: Implement IP Address Cross-Reference</title>
        <section>Story and Acceptance Criteria</section>
        <snippet>Extract IP addresses from ticket description using regex, lookup in system_inventory table. Returns device info (hostname, type, location). Async function with error handling. Status: done.</snippet>
      </doc>
      <doc>
        <path>External: LangGraph Documentation</path>
        <title>LangGraph - Run Graph Nodes in Parallel</title>
        <section>How-to Guide - Parallel Node Execution</section>
        <snippet>Fan out from Node A to B and C, then fan in to D. Nodes B and C execute concurrently in same superstep. Use state reducers (operator.add) to accumulate results. Superstep is transactional - any exception fails entire step.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/services/ticket_search_service.py</path>
        <kind>service</kind>
        <symbol>TicketSearchService.search_similar_tickets</symbol>
        <lines>58-156</lines>
        <reason>Story 2.5 service - async method to search similar tickets. Signature: async def search_similar_tickets(tenant_id, query_description, limit=5) -> tuple[List[TicketSearchResult], dict]. Will be called by ticket_search_node in workflow.</reason>
      </artifact>
      <artifact>
        <path>src/services/kb_search.py</path>
        <kind>service</kind>
        <symbol>search_knowledge_base</symbol>
        <lines>585-613</lines>
        <reason>Story 2.6 service - async convenience function for KB search. Signature: async def search_knowledge_base(tenant_id, description, kb_base_url, kb_api_key, limit=3, correlation_id) -> List[dict]. Will be called by doc_search_node in workflow.</reason>
      </artifact>
      <artifact>
        <path>src/services/ip_lookup.py</path>
        <kind>service</kind>
        <symbol>extract_and_lookup_ips</symbol>
        <lines>42-188</lines>
        <reason>Story 2.7 service - async function to extract IPs and lookup system details. Signature: async def extract_and_lookup_ips(session, tenant_id, description, correlation_id) -> List[dict]. Will be called by ip_lookup_node in workflow.</reason>
      </artifact>
      <artifact>
        <path>src/workers/tasks.py</path>
        <kind>celery_task</kind>
        <symbol>enhance_ticket</symbol>
        <lines>126-403</lines>
        <reason>Story 2.4 Celery task - entry point for enhancement workflow. This is where LangGraph workflow will be invoked. Currently processes enhancement jobs from Redis queue. Will integrate LangGraph workflow orchestration in this story.</reason>
      </artifact>
      <artifact>
        <path>src/database/models.py</path>
        <kind>model</kind>
        <symbol>TenantConfig, TicketHistory, SystemInventory, EnhancementHistory</symbol>
        <lines>1-300</lines>
        <reason>Database models for tenant isolation, ticket history (used by Story 2.5), system inventory (used by Story 2.7), and enhancement tracking. All workflow nodes must filter by tenant_id for data isolation.</reason>
      </artifact>
      <artifact>
        <path>tests/unit/test_ip_lookup.py</path>
        <kind>test</kind>
        <symbol>Various test functions</symbol>
        <lines>1-200</lines>
        <reason>Story 2.7 unit test patterns - demonstrates async testing with mocked database session. Use as reference for testing workflow nodes with mocked services.</reason>
      </artifact>
      <artifact>
        <path>tests/integration/test_kb_search_integration.py</path>
        <kind>test</kind>
        <symbol>Various integration tests</symbol>
        <lines>1-200</lines>
        <reason>Story 2.6 integration test patterns - demonstrates testing async service calls with real Redis caching. Use as reference for integration testing workflow with real service instances.</reason>
      </artifact>
    </code>
    <dependencies>
      <python>
        <package name="langgraph" version="^1.0">StateGraph, END for workflow orchestration</package>
        <package name="langchain-core" version="^0.3">Base classes and utilities for LangChain integration</package>
        <package name="sqlalchemy" version="^2.0">Async ORM for database access in workflow nodes</package>
        <package name="httpx" version="^0.25">Async HTTP client for KB API calls</package>
        <package name="redis" version="^5.0">Redis client for KB result caching</package>
        <package name="celery" version="^5.3">Task queue framework for async processing</package>
        <package name="pydantic" version="^2.0">Data validation for WorkflowState TypedDict</package>
        <package name="pytest" version="^7.4">Testing framework</package>
        <package name="pytest-asyncio" version="^0.21">Async test support</package>
      </python>
    </dependencies>
  </artifacts>

  <constraints>
    - WorkflowState must include: tenant_id, ticket_id, description, similar_tickets, kb_articles, ip_info, errors fields
    - All workflow nodes must be async functions accepting WorkflowState and returning updated WorkflowState
    - Nodes must execute in parallel using StateGraph edges (fan-out from input to all search nodes, fan-in to aggregation)
    - Error handling: Each node must catch exceptions, log errors, add to state["errors"], and continue (graceful degradation)
    - State reducer: Use operator.add for list fields (similar_tickets, kb_articles, ip_info, errors) to accumulate results from parallel nodes
    - Tenant isolation: All service calls must pass tenant_id from WorkflowState for data isolation
    - Performance: Parallel execution must reduce latency from ~30s sequential to ~10-15s parallel (AC #2)
    - Correlation ID: Pass correlation_id through workflow for debugging and tracing
    - Testing: All nodes must have unit tests with mocked services and integration tests with real services
    - Code structure: Follow project conventions - services in src/services/, workflows in src/workflows/, tests mirror src/ structure
    - Type hints: All functions must have full type hints (Pydantic models, TypedDict for state)
    - Documentation: Module docstrings must include workflow diagram (ASCII art or Mermaid) and usage examples
    - State persistence: Implement optional JSON serialization for debugging (AC #5)
    - Performance logging: Log individual node times and total workflow time (AC #6)
  </constraints>
  <interfaces>
    <interface>
      <name>WorkflowState TypedDict</name>
      <kind>TypedDict</kind>
      <signature>
class WorkflowState(TypedDict):
    tenant_id: str
    ticket_id: str
    description: str
    priority: Optional[str]
    timestamp: str
    correlation_id: str
    similar_tickets: List[Dict]  # From ticket_search_node
    kb_articles: List[Dict]      # From doc_search_node
    ip_info: List[Dict]          # From ip_lookup_node
    errors: List[Dict]           # Accumulated errors from any node
      </signature>
      <path>src/workflows/state.py (NEW)</path>
    </interface>
    <interface>
      <name>ticket_search_node</name>
      <kind>async function</kind>
      <signature>async def ticket_search_node(state: WorkflowState) -> WorkflowState</signature>
      <path>src/workflows/enhancement_workflow.py (NEW)</path>
    </interface>
    <interface>
      <name>doc_search_node</name>
      <kind>async function</kind>
      <signature>async def doc_search_node(state: WorkflowState) -> WorkflowState</signature>
      <path>src/workflows/enhancement_workflow.py (NEW)</path>
    </interface>
    <interface>
      <name>ip_lookup_node</name>
      <kind>async function</kind>
      <signature>async def ip_lookup_node(state: WorkflowState) -> WorkflowState</signature>
      <path>src/workflows/enhancement_workflow.py (NEW)</path>
    </interface>
    <interface>
      <name>aggregate_results_node</name>
      <kind>async function</kind>
      <signature>async def aggregate_results_node(state: WorkflowState) -> WorkflowState</signature>
      <path>src/workflows/enhancement_workflow.py (NEW)</path>
    </interface>
    <interface>
      <name>enhancement_graph</name>
      <kind>StateGraph</kind>
      <signature>enhancement_graph = build_enhancement_workflow()</signature>
      <path>src/workflows/enhancement_workflow.py (NEW)</path>
    </interface>
  </interfaces>
  <tests>
    <standards>
Project uses Pytest with pytest-asyncio for async test support. Testing standards:
- Framework: Pytest 7.4+ with pytest-asyncio for async functions
- Structure: tests/ mirrors src/ structure (tests/unit/, tests/integration/)
- Naming: test_*.py files, test_* functions, TestClassName for test classes
- Fixtures: Shared fixtures in tests/conftest.py for database, Redis, mocks
- Mocking: unittest.mock (AsyncMock for async, MagicMock for sync, patch for dependencies)
- Async testing: @pytest.mark.asyncio decorator for async test functions
- Coverage target: >80% code coverage for all services and workflows
- Test categories: Unit tests (mocked dependencies), Integration tests (real services with test data)
- Assertions: Clear, descriptive assertion messages; test one concept per test function
- Edge cases: Test success path, failure path, edge cases, boundary conditions
- Patterns from existing tests:
  * test_ip_lookup.py: Async service testing with mocked AsyncSession
  * test_kb_search.py: Service testing with mocked HTTP client and Redis
  * test_celery_tasks.py: Celery task testing with mocked database and services
    </standards>
    <locations>
- tests/unit/test_langgraph_workflow.py (NEW) - Unit tests for workflow nodes and state management
- tests/integration/test_langgraph_integration.py (NEW) - Integration tests with real service instances
- tests/conftest.py - Shared fixtures for test environment setup
    </locations>
    <ideas>
Test Ideas Mapped to Acceptance Criteria:

AC #1 (Workflow defined with nodes):
- Test: Workflow initialization creates StateGraph with correct nodes (ticket_search, doc_search, ip_lookup, aggregate_results)
- Test: Each node is registered in workflow graph
- Test: Workflow edges configured correctly (parallel fan-out, fan-in to aggregation)
- Test: WorkflowState TypedDict has all required fields

AC #2 (Nodes execute concurrently):
- Test: Parallel node execution - verify all three search nodes execute concurrently (use timing assertions)
- Test: Total workflow time is ~max(node_times), not sum(node_times)
- Test: Parallel execution reduces latency (mock services with delays, assert parallel faster than sequential)

AC #3 (Workflow aggregates results):
- Test: aggregate_results_node combines outputs from all search nodes
- Test: State contains similar_tickets, kb_articles, ip_info after aggregation
- Test: Aggregation logs stats ("Found X similar tickets, Y KB articles, Z IPs")
- Test: Empty results handled gracefully (all nodes return empty lists)

AC #4 (Failed nodes don't block workflow):
- Test: ticket_search_node failure - other nodes continue, workflow completes with partial results
- Test: doc_search_node failure - other nodes continue
- Test: ip_lookup_node failure - other nodes continue
- Test: All 3 nodes fail - workflow completes with only errors in state
- Test: Error added to state["errors"] with node name, error message, timestamp

AC #5 (Workflow state persisted for debugging):
- Test: WorkflowState serializes to JSON correctly
- Test: State stored in memory with ticket_id as key
- Test: State history maintains last 100 entries
- Test: Old states auto-cleaned after 1 hour (TTL)

AC #6 (Workflow execution time logged):
- Test: Individual node execution times logged
- Test: Total workflow time logged
- Test: Performance breakdown logged ("Parallel execution reduced latency from Xs to Ys")

AC #7 (Unit tests verify execution and aggregation):
- Test: ticket_search_node with mocked TicketSearchService
- Test: doc_search_node with mocked KB search function
- Test: ip_lookup_node with mocked extract_and_lookup_ips
- Test: State updates correctly in each node
- Test: Correlation ID passed through workflow
- Test: Tenant isolation (tenant_id passed to all service calls)
- Test: Integration with enhance_ticket Celery task (Story 2.4)
    </ideas>
  </tests>
</story-context>
