<story-context id="bmad/bmm/workflows/4-implementation/story-context/template" v="1.0">
  <metadata>
    <epicId>2</epicId>
    <storyId>2.9</storyId>
    <title>Integrate OpenAI GPT-4o-mini for Context Synthesis</title>
    <status>drafted</status>
    <generatedAt>2025-11-02</generatedAt>
    <generator>BMAD Story Context Workflow</generator>
    <sourceStoryPath>docs/stories/2-9-integrate-openai-gpt4-for-context-synthesis.md</sourceStoryPath>
  </metadata>

  <story>
    <asA>an enhancement agent</asA>
    <iWant>to use LLM to analyze gathered context and generate actionable insights</iWant>
    <soThat>technicians receive synthesized recommendations, not just raw data</soThat>
    <tasks>
      <task id="1" title="Set Up OpenRouter API Client Configuration">
        - Add environment variables (OPENROUTER_API_KEY, OPENROUTER_BASE_URL, etc.)
        - Update src/config.py Settings class with OpenRouter fields
        - Verify Kubernetes Secret manifests for production
        - Create OpenRouter client initialization in src/services/llm_synthesis.py
      </task>
      <task id="2" title="Define System Prompt and User Template">
        - Create src/prompts/enhancement_prompts.py
        - Define ENHANCEMENT_SYSTEM_PROMPT (role, guidelines, format, constraints)
        - Create ENHANCEMENT_USER_TEMPLATE with placeholders
        - Test prompt templates with sample data
      </task>
      <task id="3" title="Implement Context Formatting Helpers">
        - Implement format_tickets() helper for similar tickets
        - Implement format_kb_articles() helper for KB articles
        - Implement format_ip_info() helper for system information
        - Test formatting helpers with mock data
      </task>
      <task id="4" title="Implement LLM Synthesis Function">
        - Create synthesize_enhancement(context: WorkflowState) function
        - Implement prompt assembly using formatting helpers
        - Implement OpenRouter API call with timeout (30s)
        - Implement word limit enforcement (500 words max)
        - Implement cost tracking (token usage logging)
        - Implement error handling and fallback (graceful degradation)
      </task>
      <task id="5" title="Unit Tests for Synthesis">
        - Create tests/unit/test_llm_synthesis.py
        - Test happy path (successful synthesis)
        - Test edge cases (empty context, single element, long context)
        - Test error cases (timeout, 401, 5xx, invalid response)
        - Test word truncation logic
        - Test formatting helpers
      </task>
      <task id="6" title="Integration with Story 2.8">
        - Verify WorkflowState type compatibility
        - Create integration test with LangGraph workflow
        - Test timeout behavior in context
      </task>
      <task id="7" title="Configuration & Documentation">
        - Document environment variables
        - Document LLM configuration options
        - Update system prompts documentation
        - Add cost tracking documentation
      </task>
      <task id="8" title="Validation Against Acceptance Criteria">
        - Validate all 11 acceptance criteria are met
        - Complete implementation checklist
      </task>
    </tasks>
  </story>

  <acceptanceCriteria>
    <criterion id="AC1" title="OpenRouter API Client Configured">
      - API key loaded from OPENROUTER_API_KEY environment variable
      - Base URL configured as https://openrouter.ai/api/v1
      - Site URL and app name headers included per OpenRouter requirements
      - Client initialization validates API key format (non-empty string)
    </criterion>
    <criterion id="AC2" title="System Prompt Defined">
      - System prompt articulates agent role: MSP technician assistant
      - Behavior guidelines: concise, actionable, fact-based
      - Output format: Clear sections (Similar Tickets, Documentation, System Info, Recommended Next Steps)
      - Constraints: No speculation beyond context, maximum 500 words
    </criterion>
    <criterion id="AC3" title="Prompt Template Implemented">
      - Template accepts: ticket_id, description, priority, gathered context
      - Formats context summaries into readable format for LLM
      - Placeholder variables properly substituted with actual context data
      - Complete context passed to LLM for synthesis
    </criterion>
    <criterion id="AC4" title="LLM Output Formatted Correctly">
      - Markdown-formatted sections with headers (##)
      - Source citations where applicable (e.g., "Ticket TKT-123 resolved by...")
      - Markdown-compatible for display in ServiceDesk Plus
      - Special characters and formatting preserved correctly
    </criterion>
    <criterion id="AC5" title="500-Word Limit Enforced">
      - Enhancement output validated against 500-word maximum
      - Word count calculated after LLM response received
      - Output truncated if exceeding limit with indicator
      - Truncation preserves complete sentences (no mid-sentence cuts)
    </criterion>
    <criterion id="AC6" title="API Timeout Configured">
      - Request timeout set to 30 seconds for LLM synthesis calls
      - Timeout handling returns fallback (formatted context without synthesis)
      - Timeout logged as warning with correlation ID
      - Fallback output indicates AI synthesis was unavailable
    </criterion>
    <criterion id="AC7" title="Cost Tracking Implemented">
      - Token usage logged after each API call (input/output/total)
      - Log includes correlation ID, tenant_id, ticket_id for cost attribution
      - Cost tracking supports future billing/monitoring of LLM expenses
      - Token logs structured (JSON format) for analytics aggregation
    </criterion>
    <criterion id="AC8" title="Error Handling for API Failures">
      - Network errors: Log error, return fallback
      - Authentication errors (401): Log security event, return fallback
      - API errors (5xx): Log with retry indicator, return fallback
      - Invalid responses: Log error, return fallback
      - All error cases result in formatted context without synthesis (graceful degradation)
    </criterion>
    <criterion id="AC9" title="Unit Tests Cover Happy Path">
      - Test successful synthesis with mock LLM response
      - Mock response includes properly formatted sections
      - Verify output contains expected structure and content
      - Verify word count constraint applied
    </criterion>
    <criterion id="AC10" title="Unit Tests Cover Edge Cases">
      - Test with empty context (no similar tickets, KB articles, IP info)
      - Test with single context element present
      - Test with very long context (verify truncation)
      - Test with special characters in context
    </criterion>
    <criterion id="AC11" title="Unit Tests Cover Failure Cases">
      - Test LLM timeout: Verify fallback returns context without synthesis
      - Test API authentication failure: Verify fallback without retry
      - Test API 5xx error: Verify fallback without retry
      - Test invalid API response: Verify fallback without crash
    </criterion>
  </acceptanceCriteria>

  <artifacts>
    <docs>
      <doc>
        <path>docs/PRD.md</path>
        <title>Product Requirements Document</title>
        <section>AI Processing & Enhancement (FR010-FR014)</section>
        <snippet>System shall use LLM (OpenAI GPT-4) to analyze gathered context and synthesize relevant insights. Format enhancement output with clear sections. Limit output to maximum 500 words to prevent ticket bloat. Include confidence scores or source citations.</snippet>
      </doc>
      <doc>
        <path>docs/architecture.md</path>
        <title>Decision Architecture</title>
        <section>AI/ML Stack & LLM Provider</section>
        <snippet>LangGraph 1.0+ for AI workflow orchestration. OpenRouter API as multi-model LLM gateway (OpenAI SDK compatible). OpenAI Python SDK for API client (works with OpenRouter). HTTPX for async HTTP client.</snippet>
      </doc>
      <doc>
        <path>docs/tech-spec-epic-2.md</path>
        <title>Epic 2 Technical Specification</title>
        <section>Story 2.9: LLM Synthesis Implementation</section>
        <snippet>OpenRouter API client configuration with timeout (30s), system prompt definition, context formatting helpers, word limit enforcement (500 words), cost tracking (token usage logging), error handling with fallback.</snippet>
      </doc>
      <doc>
        <path>docs/stories/2-8-integrate-langgraph-workflow-orchestration.md</path>
        <title>Story 2.8: LangGraph Workflow</title>
        <section>Integration Point for Story 2.9</section>
        <snippet>LangGraph workflow returns WorkflowState containing similar_tickets, kb_articles, ip_info. Parallel execution reduces latency. Context nodes handle failures gracefully. Story 2.9 consumes WorkflowState output.</snippet>
      </doc>
      <doc>
        <path>https://openrouter.ai/docs/community/open-ai-sdk.mdx</path>
        <title>OpenRouter SDK Documentation</title>
        <section>OpenAI SDK Integration</section>
        <snippet>Use OpenAI SDK with base_url="https://openrouter.ai/api/v1". Include HTTP-Referer and X-Title headers for rankings. Supports async/await with AsyncOpenAI client.</snippet>
      </doc>
    </docs>
    <code>
      <artifact>
        <path>src/config.py</path>
        <kind>configuration</kind>
        <symbol>Settings</symbol>
        <lines>15-127</lines>
        <reason>Configuration class where OpenRouter settings must be added. Uses Pydantic Settings with AI_AGENTS_ prefix for environment variables.</reason>
      </artifact>
      <artifact>
        <path>src/workflows/state.py</path>
        <kind>interface</kind>
        <symbol>WorkflowState</symbol>
        <lines>14-74</lines>
        <reason>TypedDict defining the complete workflow state from Story 2.8. This is the input interface for the synthesis function.</reason>
      </artifact>
      <artifact>
        <path>src/workflows/enhancement_workflow.py</path>
        <kind>workflow</kind>
        <symbol>execute_context_gathering</symbol>
        <lines>572-678</lines>
        <reason>Function that returns WorkflowState with similar_tickets, kb_articles, ip_info. The output from Story 2.8 that feeds into Story 2.9 synthesis.</reason>
      </artifact>
      <artifact>
        <path>tests/conftest.py</path>
        <kind>test-infrastructure</kind>
        <symbol>pytest fixtures</symbol>
        <lines>all</lines>
        <reason>Contains test fixtures for mocking external services. Patterns to follow for mocking OpenRouter API calls.</reason>
      </artifact>
      <artifact>
        <path>tests/unit/test_langgraph_workflow.py</path>
        <kind>test-example</kind>
        <symbol>test patterns</symbol>
        <lines>all</lines>
        <reason>Example of async testing patterns with AsyncMock for Story 2.8. Similar patterns needed for Story 2.9 LLM synthesis tests.</reason>
      </artifact>
    </code>
    <dependencies>
      <python>
        <package name="openai" version="latest" reason="OpenAI SDK for OpenRouter API calls (async support)" />
        <package name="httpx" version=">=0.25.2" reason="Already in project - async HTTP client for timeout handling" />
        <package name="pydantic" version=">=2.5.0" reason="Already in project - data validation and settings" />
        <package name="loguru" version=">=0.7.2" reason="Already in project - structured logging" />
        <package name="langgraph" version="1.0+" reason="Already in project (Story 2.8) - WorkflowState integration" />
        <package name="pytest-asyncio" version=">=0.21.1" reason="Already in dev dependencies - async test support" />
      </python>
    </dependencies>
  </artifacts>

  <constraints>
    <constraint id="1" category="architecture">
      Integration Point: Story 2.9 synthesis function must accept WorkflowState from Story 2.8 LangGraph workflow (src/workflows/state.py)
    </constraint>
    <constraint id="2" category="configuration">
      Environment Variables: All settings must use AI_AGENTS_ prefix (e.g., AI_AGENTS_OPENROUTER_API_KEY) per existing Settings class pattern
    </constraint>
    <constraint id="3" category="performance">
      Timeout: LLM synthesis API calls must timeout after 30 seconds (per AC #6 and NFR001 120s total budget)
    </constraint>
    <constraint id="4" category="output">
      Word Limit: Enhancement output must not exceed 500 words (per FR013) to prevent ticket bloat
    </constraint>
    <constraint id="5" category="error-handling">
      Graceful Degradation: All API failures must return fallback (formatted context without synthesis) per NFR003 99% success rate
    </constraint>
    <constraint id="6" category="logging">
      Structured Logging: Use Loguru with JSON-compatible structured logs including correlation_id, tenant_id, ticket_id (per existing patterns)
    </constraint>
    <constraint id="7" category="testing">
      Test Pattern: Use pytest with AsyncMock for external service calls, following patterns from test_langgraph_workflow.py
    </constraint>
    <constraint id="8" category="code-style">
      Code Quality: Black formatting (line-length=100), Ruff linting, type hints required (per pyproject.toml)
    </constraint>
  </constraints>

  <interfaces>
    <interface id="1" name="synthesize_enhancement" kind="function">
      <signature>async def synthesize_enhancement(context: WorkflowState) -> str</signature>
      <path>src/services/llm_synthesis.py (NEW)</path>
      <description>Main entry point for LLM synthesis. Accepts WorkflowState from Story 2.8, returns markdown-formatted enhancement string (max 500 words).</description>
    </interface>
    <interface id="2" name="WorkflowState" kind="TypedDict">
      <signature>class WorkflowState(TypedDict): tenant_id, ticket_id, description, priority, similar_tickets, kb_articles, ip_info, errors...</signature>
      <path>src/workflows/state.py</path>
      <description>Complete workflow state from LangGraph (Story 2.8). Input to synthesis function.</description>
    </interface>
    <interface id="3" name="OpenRouter API" kind="REST">
      <signature>POST https://openrouter.ai/api/v1/chat/completions (OpenAI SDK compatible)</signature>
      <path>External API</path>
      <description>OpenRouter API Gateway for multi-model LLM access. Requires API key, HTTP-Referer, and X-Title headers.</description>
    </interface>
    <interface id="4" name="Settings.openrouter_*" kind="configuration">
      <signature>openrouter_api_key: str, openrouter_base_url: str, openrouter_site_url: str, openrouter_app_name: str</signature>
      <path>src/config.py</path>
      <description>Configuration fields to be added to Settings class for OpenRouter API client initialization.</description>
    </interface>
  </interfaces>
  <tests>
    <standards>
      Testing Framework: Pytest with pytest-asyncio for async test support (asyncio_mode="auto" in pyproject.toml).
      Mocking Pattern: Use unittest.mock.AsyncMock for async external service calls (OpenRouter API).
      Test Organization: Unit tests in tests/unit/test_llm_synthesis.py, integration tests in tests/integration/.
      Coverage Requirement: >80% test coverage for synthesis module per Story 2.9 acceptance criteria.
      Fixture Pattern: Follow tests/conftest.py patterns for reusable test fixtures (mock clients, sample data).
      Test Structure: Separate tests for happy path (AC #9), edge cases (AC #10), and failure cases (AC #11).
      Async Testing: All synthesis tests must use async def test_* and await calls, leveraging pytest-asyncio.
    </standards>
    <locations>
      <location>tests/unit/test_llm_synthesis.py</location>
      <location>tests/integration/test_synthesis_with_langgraph.py</location>
      <location>tests/fixtures/sample_context.json</location>
    </locations>
    <ideas>
      <test_idea ac="AC1,AC9">
        Test: test_successful_synthesis_with_valid_context
        Goal: Mock OpenRouter API response, call synthesize_enhancement(), verify output structure (sections, word count)
        Assertions: Output contains "Similar Tickets", "Recommended Next Steps", word count ≤ 500
      </test_idea>
      <test_idea ac="AC5,AC9">
        Test: test_word_limit_enforcement_truncation
        Goal: Mock LLM response >500 words, verify truncation applied with indicator
        Assertions: Output ≤ 500 words, contains "[Output truncated to 500-word limit]"
      </test_idea>
      <test_idea ac="AC6,AC11">
        Test: test_timeout_returns_fallback
        Goal: Mock API call to raise asyncio.TimeoutError after 30s
        Assertions: Returns fallback (formatted context), logs timeout warning, no exception raised
      </test_idea>
      <test_idea ac="AC8,AC11">
        Test: test_authentication_error_returns_fallback
        Goal: Mock API to raise HTTPStatusError with status=401
        Assertions: Returns fallback, logs security event, no retry attempted
      </test_idea>
      <test_idea ac="AC8,AC11">
        Test: test_server_error_returns_fallback
        Goal: Mock API to raise HTTPStatusError with status=500
        Assertions: Returns fallback, logs error with correlation_id, graceful degradation
      </test_idea>
      <test_idea ac="AC10">
        Test: test_synthesis_with_empty_context
        Goal: Pass WorkflowState with empty similar_tickets, kb_articles, ip_info
        Assertions: Synthesis still generates valid output, no exceptions
      </test_idea>
      <test_idea ac="AC10">
        Test: test_synthesis_with_single_context_element
        Goal: Pass WorkflowState with only similar_tickets populated
        Assertions: Synthesis produces output focusing on available context
      </test_idea>
      <test_idea ac="AC3,AC9">
        Test: test_format_tickets_with_data
        Goal: Call format_tickets() helper with mock ticket data
        Assertions: Returns markdown list with ticket IDs, resolutions, relevance scores
      </test_idea>
      <test_idea ac="AC3,AC9">
        Test: test_format_kb_articles_empty_returns_fallback
        Goal: Call format_kb_articles() with empty list
        Assertions: Returns "No relevant documentation found." message
      </test_idea>
      <test_idea ac="AC7">
        Test: test_cost_tracking_logs_token_usage
        Goal: Mock API response with usage metadata, verify token logging
        Assertions: Log contains input_tokens, output_tokens, total_tokens, correlation_id, tenant_id
      </test_idea>
    </ideas>
  </tests>
</story-context>
